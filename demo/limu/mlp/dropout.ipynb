{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e2462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\numpy\\__init__.py:148: UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http://github.com/IntelPython/mkl-service\n",
      "  from . import _distributor_init\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.8 from \"d:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\python.exe\"\n  * The NumPy version is: \"1.21.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: 找不到指定的模块。\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32md:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\numpy\\core\\__init__.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m multiarray\n\u001b[0;32m     23\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\numpy\\core\\multiarray.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m overrides\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _multiarray_umath\n",
      "File \u001b[1;32md:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\numpy\\core\\overrides.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtextwrap\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_multiarray_umath\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_inspect\u001b[39;00m \u001b[39mimport\u001b[39;00m getargspec\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _multiarray_umath: 找不到指定的模块。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01md2l\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m torch \u001b[38;5;28;01mas\u001b[39;00m d2l\n",
      "File \u001b[1;32md:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\__init__.py:613\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[39mreturn\u001b[39;00m path\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    612\u001b[0m \u001b[39m# Shared memory manager needs to know the exact location of manager executable\u001b[39;00m\n\u001b[1;32m--> 613\u001b[0m _C\u001b[39m.\u001b[39;49m_initExtension(manager_path())\n\u001b[0;32m    614\u001b[0m \u001b[39mdel\u001b[39;00m manager_path\n\u001b[0;32m    616\u001b[0m \u001b[39m# Appease the type checker: it can't deal with direct setting of globals().\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[39m# Note that we will see \"too many\" functions when reexporting this way; there\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[39m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[39m# so that this import is good enough\u001b[39;00m\n",
      "File \u001b[1;32md:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\cuda\\__init__.py:685\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m profiler\n\u001b[0;32m    684\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m nvtx\n\u001b[1;32m--> 685\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m amp\n",
      "File \u001b[1;32md:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\cuda\\amp\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautocast_mode\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast, custom_fwd, custom_bwd  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgrad_scaler\u001b[39;00m \u001b[39mimport\u001b[39;00m GradScaler\n",
      "File \u001b[1;32md:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\cuda\\amp\\autocast_mode.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcollections\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     HAS_NUMPY \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32md:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\numpy\\__init__.py:150\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39m# Allow distributors to run custom init code\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init\n\u001b[1;32m--> 150\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[0;32m    151\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    152\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n",
      "File \u001b[1;32md:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\numpy\\core\\__init__.py:48\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[39mIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39m\"\"\"\u001b[39m \u001b[39m%\u001b[39m (sys\u001b[39m.\u001b[39mversion_info[\u001b[39m0\u001b[39m], sys\u001b[39m.\u001b[39mversion_info[\u001b[39m1\u001b[39m], sys\u001b[39m.\u001b[39mexecutable,\n\u001b[0;32m     47\u001b[0m         __version__, exc)\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[0;32m     49\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[39mfor\u001b[39;00m envkey \u001b[39min\u001b[39;00m env_added:\n",
      "\u001b[1;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.8 from \"d:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\python.exe\"\n  * The NumPy version is: \"1.21.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: 找不到指定的模块。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "def dropout_layer(X, dropout ):\n",
    "    assert 0 <= dropout <= 1\n",
    "    # 在本情况中，所有元素都被丢弃\n",
    "    if dropout == 1:\n",
    "        return torch.zeros_like(X)\n",
    "    # 在本情况中，所有元素都被保留\n",
    "    if dropout == 0:\n",
    "        return X\n",
    "    # 做乘法比选值来得快\n",
    "    mask = (torch.rand(X.shape) > dropout).float()     # mask是标志0或者1的标志位\n",
    "    return mask * X / (1.0 - dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d51a35df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11., 12., 13., 14., 15.]]),\n",
       " tensor([[ 0.0000,  1.4286,  2.8571,  0.0000,  5.7143,  0.0000,  0.0000, 10.0000],\n",
       "         [ 0.0000, 12.8571,  0.0000,  0.0000, 17.1429,  0.0000,  0.0000, 21.4286]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype = torch.float32).reshape((2, 8))\n",
    "X, dropout_layer(X, 0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch_practice_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3d7662c7a11a1971edb7ceb39f85592109b843965b3975bc3a6316b4b6d1b58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
