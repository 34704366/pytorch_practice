{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./dataset/Delaware.csv\")\n",
    "# df = df[df.REGION == \"New York\"]\n",
    "\n",
    "df_use = df[[\"REGION\", \"YEAR\", \"WEEK\", \"ili_ratio\"]]\n",
    "df_use.index = range(len(df_use))\n",
    "\n",
    "df_use = (df_use.loc[:, [\"ili_ratio\"]])  # 只用ili_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "     ili_ratio\n0     0.001001\n1     0.003686\n2     0.003370\n3     0.004605\n4     0.002223\n..         ...\n624   0.011423\n625   0.009824\n626   0.009270\n627   0.012565\n628   0.013683\n\n[629 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ili_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001001</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.003686</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.003370</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.004605</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.002223</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>624</th>\n      <td>0.011423</td>\n    </tr>\n    <tr>\n      <th>625</th>\n      <td>0.009824</td>\n    </tr>\n    <tr>\n      <th>626</th>\n      <td>0.009270</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>0.012565</td>\n    </tr>\n    <tr>\n      <th>628</th>\n      <td>0.013683</td>\n    </tr>\n  </tbody>\n</table>\n<p>629 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/Delaware.csv\")\n",
    "# df = df[df.REGION == \"Delaware\"]\n",
    "\n",
    "df_use = df[[\"REGION\", \"YEAR\", \"WEEK\", \"ili_ratio\"]]\n",
    "df_use.index = range(len(df_use))\n",
    "\n",
    "df_use = (df_use.loc[:, [\"ili_ratio\"]])  # 只用ili_ratio\n",
    "df_use"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "     New_cases\n0           73\n1          133\n2          184\n3          107\n4          410\n..         ...\n655      48473\n656      14684\n657      72634\n658      79567\n659      91288\n\n[660 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>New_cases</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>133</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>184</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>107</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>410</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>655</th>\n      <td>48473</td>\n    </tr>\n    <tr>\n      <th>656</th>\n      <td>14684</td>\n    </tr>\n    <tr>\n      <th>657</th>\n      <td>72634</td>\n    </tr>\n    <tr>\n      <th>658</th>\n      <td>79567</td>\n    </tr>\n    <tr>\n      <th>659</th>\n      <td>91288</td>\n    </tr>\n  </tbody>\n</table>\n<p>660 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/covid19/france_new_cases.csv\")\n",
    "\n",
    "df_use = df[[\"New_cases\"]]\n",
    "df_use = df_use[:660]\n",
    "df_use.index = range(len(df_use))\n",
    "\n",
    "df_use"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "     New_cases  tavg\n0           73   9.1\n1          133   7.4\n2          184   7.8\n3          107   8.9\n4          410   8.5\n..         ...   ...\n655      48473   3.9\n656      14684   2.5\n657      72634   2.5\n658      79567   6.7\n659      91288   9.3\n\n[660 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>New_cases</th>\n      <th>tavg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>73</td>\n      <td>9.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>133</td>\n      <td>7.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>184</td>\n      <td>7.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>107</td>\n      <td>8.9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>410</td>\n      <td>8.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>655</th>\n      <td>48473</td>\n      <td>3.9</td>\n    </tr>\n    <tr>\n      <th>656</th>\n      <td>14684</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>657</th>\n      <td>72634</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>658</th>\n      <td>79567</td>\n      <td>6.7</td>\n    </tr>\n    <tr>\n      <th>659</th>\n      <td>91288</td>\n      <td>9.3</td>\n    </tr>\n  </tbody>\n</table>\n<p>660 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/covid19/france_new_cases _temp.csv\")\n",
    "\n",
    "df_use = df[[\"New_cases\", \"tavg\"]]\n",
    "df_use = df_use[:660]\n",
    "df_use.index = range(len(df_use))\n",
    "\n",
    "df_use"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/elec/oneminute.csv')\n",
    "\n",
    "df_use = df[['p']]\n",
    "df_use.index = range(len(df_use))\n",
    "df_use = df_use[:500]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def nn_seq_us(batch_size, step):\n",
    "    print('data processing...')\n",
    "    dataset = df_use\n",
    "    # split\n",
    "    train = dataset[:int(len(dataset) * 0.6)]\n",
    "    val = dataset[int(len(dataset) * 0.6):int(len(dataset) * 0.85)]\n",
    "    test = dataset[int(len(dataset) * 0.85):len(dataset)]\n",
    "    m, n = np.max(train[train.columns[0]]), np.min(train[train.columns[0]])\n",
    "\n",
    "    def process(data, batch_size, shuffle):\n",
    "        load = data[data.columns[:]]\n",
    "        load = load.values\n",
    "        data = data.values.tolist()\n",
    "        load = (load - n) / (m - n)\n",
    "\n",
    "        # load = data[data.columns[0]]\n",
    "        # load = load.tolist()\n",
    "        # data = data.values.tolist()\n",
    "        # load = (load - n) / (m - n)\n",
    "\n",
    "        seq = []\n",
    "        for i in range(len(data) - step):\n",
    "            train_seq = []\n",
    "            train_label = []\n",
    "            for j in range(i, i + step):\n",
    "                x = [load[j]]\n",
    "                train_seq.append(x)\n",
    "            # for c in range(2, 8):\n",
    "            #     train_seq.append(data[i + step][c])\n",
    "            train_label.append(load[i + step])\n",
    "            train_seq = torch.FloatTensor(train_seq)\n",
    "            train_label = torch.FloatTensor(train_label).view(-1)\n",
    "            seq.append((train_seq, train_label))\n",
    "\n",
    "        # print(seq[-1])\n",
    "        seq = MyDataset(seq)\n",
    "        seq = DataLoader(dataset=seq, batch_size=batch_size, shuffle=shuffle, num_workers=0, drop_last=True)\n",
    "\n",
    "        return seq\n",
    "\n",
    "    data_train = process(train, batch_size, True)\n",
    "    data_validate = process(val, batch_size, True)\n",
    "    data_test = process(test, batch_size, False)\n",
    "\n",
    "    return data_train, data_validate, data_test, m, n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, batch_size, device):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.num_directions = 1  # 单向LSTM\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        batch_size, seq_len = input_seq.shape[0], input_seq.shape[1]\n",
    "        h_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        c_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        # output(batch_size, seq_len, num_directions * hidden_size)\n",
    "        output, _ = self.lstm(input_seq, (h_0, c_0))  # output(5, 30, 64)\n",
    "        pred = self.linear(output)  # (5, 30, 1)\n",
    "        pred = pred[:, -1, :]  # (5, 1)\n",
    "        return pred\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR as StepLR\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "def get_val_loss(model, Val, loss_function, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    for (seq, label) in Val:\n",
    "        seq = seq.to(device)\n",
    "        label = label.to(device)\n",
    "        y_pred = model(seq)\n",
    "        loss = loss_function(y_pred, label)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "    return sum(val_loss)/len(val_loss)# MSE\n",
    "\n",
    "\n",
    "def lstm_train(data_train, Val, path, input_size=1, hidden_size=10, num_layers=2, output_size = 1, batch_size = 5, optimizer = 'adam', max_epochs = 20, lr = 0.01, device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")):\n",
    "    weight_decay = 0.0001\n",
    "    step_size = 5\n",
    "    gamma = 0.1\n",
    "\n",
    "\n",
    "    model = LSTM(input_size, hidden_size, num_layers, output_size, batch_size=batch_size, device=device).to(device)\n",
    "\n",
    "    loss_function = nn.MSELoss().to(device)\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
    "                                     weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr,\n",
    "                                    momentum=0.9, weight_decay=weight_decay)\n",
    "    scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    # training\n",
    "    min_epochs = 10\n",
    "    best_model = None\n",
    "    min_val_loss = 5\n",
    "\n",
    "    min_train_loss = 10086\n",
    "    loss = 10\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        train_loss = []\n",
    "        for (seq, label) in data_train:\n",
    "            seq = seq.to(device)\n",
    "            seq.resize_(batch_size, step, input_size)    # (1, 18, 1, 2) -> (1, 18, 2)\n",
    "\n",
    "            label = label.to(device)\n",
    "            y_pred = model(seq)\n",
    "\n",
    "            if epoch == 10:\n",
    "                print(f'seq:{seq.size()}')\n",
    "                print(f'seq:{label.size()}')\n",
    "                print(f'y_pred:{y_pred.size()}')\n",
    "\n",
    "            loss = loss_function(y_pred, label)\n",
    "            train_loss.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # # validation\n",
    "        # val_loss = get_val_loss(model, Val, loss_function, device)\n",
    "        # if epoch > min_epochs and val_loss < min_val_loss:\n",
    "        #     min_val_loss = val_loss\n",
    "        #     best_model = deepcopy(model)\n",
    "        #\n",
    "        # if epoch % 10 == 0:\n",
    "        #     print('epoch {:03d} train_loss {:.8f} val_loss {:.8f}'.format(epoch, np.mean(train_loss), val_loss))\n",
    "\n",
    "        if epoch > min_epochs and loss < min_train_loss:\n",
    "            min_train_loss = loss\n",
    "            best_model = deepcopy(model)\n",
    "            print(type(model))\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print('epoch {:03d} train_loss {:.8f}'.format(epoch, np.mean(train_loss)))\n",
    "\n",
    "        model.train()\n",
    "\n",
    "    state = {'models': best_model.state_dict()}\n",
    "    torch.save(state, path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "def get_mse(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.sum((y_true - y_pred) ** 2) / len(y_true)\n",
    "\n",
    "\n",
    "def get_mape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute mean absolute percentage error (MAPE)\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "# def lstm_test(data_test, path, m, n, input_size = 1,  hidden_size = 10, num_layers = 2, output_size = 1, batch_size = 5, device = torch.device('cpu')):\n",
    "def lstm_test(data_test, path, m, n, input_size, hidden_size, num_layers, output_size, batch_size, device):\n",
    "    pred = []\n",
    "    y = []\n",
    "    print('loading models...')\n",
    "\n",
    "    model = LSTM(input_size, hidden_size, num_layers, output_size, batch_size=batch_size, device=device).to(device)\n",
    "    model.load_state_dict(torch.load(path)['models'])\n",
    "    model.eval()\n",
    "    print('predicting...')\n",
    "    for (seq, target) in data_test:\n",
    "        target = list(chain.from_iterable(target.data.tolist()))\n",
    "        y.extend(target)\n",
    "        seq = seq.to(device)\n",
    "        seq.resize_(batch_size, step, input_size)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(seq)\n",
    "            y_pred = list(chain.from_iterable(y_pred.data.tolist()))\n",
    "            pred.extend(y_pred)\n",
    "\n",
    "    y, pred = np.array(y), np.array(pred)\n",
    "    y = (m - n) * y + n\n",
    "    pred = (m - n) * pred + n\n",
    "    print('mape:', get_mape(y, pred))\n",
    "    print('mse:', get_mse(y, pred))\n",
    "\n",
    "    # plot\n",
    "    x = [i for i in range(1, y.shape[0] + 1)]\n",
    "    x_smooth = np.linspace(np.min(x), np.max(x), 900)\n",
    "    y_smooth = make_interp_spline(x, y)(x_smooth)\n",
    "    plt.plot(x_smooth, y_smooth, c='green', marker='*', ms=1, alpha=0.75, label='true')\n",
    "\n",
    "    y_smooth = make_interp_spline(x, pred)(x_smooth)\n",
    "    plt.plot(x_smooth, y_smooth, c='red', marker='o', ms=1, alpha=0.75, label='pred')\n",
    "    plt.grid(axis='y')\n",
    "    plt.legend()\n",
    "    # plt.savefig(\"./new.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def future_lstm_test(data_test, path, m, n, input_size, hidden_size, num_layers, output_size, batch_size, device):\n",
    "    pred = []\n",
    "    y = []\n",
    "    print('loading models...')\n",
    "\n",
    "    model = LSTM(input_size, hidden_size, num_layers, output_size, batch_size=batch_size, device=device).to(device)\n",
    "    model.load_state_dict(torch.load(path)['models'])\n",
    "    model.eval()\n",
    "    print('predicting...')\n",
    "\n",
    "\n",
    "    y_pred = 0\n",
    "    seq = []\n",
    "    label = []\n",
    "    ss = [(seq, target) for (seq, target) in data_test]\n",
    "    for i in range(len(ss)):\n",
    "        label.append(ss[i][1][0])\n",
    "\n",
    "    y = label\n",
    "\n",
    "    # label = list(chain.from_iterable(label.tolist()))\n",
    "    ss = ss[0]\n",
    "    # print(ss)\n",
    "    for i in range(50):\n",
    "\n",
    "        seq = ss[0].to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(seq)\n",
    "            # print(f'seq{seq};')\n",
    "            for i in range(len(seq[0]) - 1):\n",
    "                seq[0][i] = seq[0][i+1]\n",
    "            seq[0][-1] = y_pred\n",
    "            # print(f'pred: {y_pred}')\n",
    "            y_pred = list(chain.from_iterable(y_pred.data.tolist()))\n",
    "            pred.extend(y_pred)\n",
    "\n",
    "\n",
    "    # print(f'y_pred is {y_pred}')\n",
    "\n",
    "    y = []\n",
    "    for i in range(len(label)):\n",
    "        y.append(label[i].detach().numpy()[0])\n",
    "\n",
    "\n",
    "    y, pred = np.array(y), np.array(pred)\n",
    "    y = (m - n) * y + n\n",
    "    pred = (m - n) * pred + n\n",
    "    # print('mape:', get_mape(y, pred))\n",
    "    # print('mse:', get_mse(y, pred))\n",
    "    print(len(y))\n",
    "    print(len(pred))\n",
    "\n",
    "    # plot\n",
    "    # x = [i for i in range(1, y.shape[0] + 1)]\n",
    "    x = [i for i in range(1, 50+1)]\n",
    "    x_smooth = np.linspace(np.min(x), np.max(x), 900)\n",
    "    y_smooth = make_interp_spline(x, y[:50])(x_smooth)\n",
    "    plt.plot(x_smooth, y_smooth, c='green', marker='*', ms=1, alpha=0.75, label='true')\n",
    "\n",
    "    # x = [i for i in range(1, pred.shape[0] + 1)]\n",
    "    x = [i for i in range(1, 50+1)]\n",
    "    y_smooth = make_interp_spline(x, pred[:50])(x_smooth)\n",
    "    plt.plot(x_smooth, y_smooth, c='red', marker='o', ms=1, alpha=0.75, label='pred')\n",
    "    plt.grid(axis='y')\n",
    "    plt.legend()\n",
    "    # plt.savefig(\"./new.png\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "data processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([1, 2])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000 train_loss 0.02575524\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "seq:torch.Size([1, 18, 2])\n",
      "seq:torch.Size([1, 2])\n",
      "y_pred:torch.Size([1, 1])\n",
      "epoch 010 train_loss 0.02108601\n",
      "<class '__main__.LSTM'>\n",
      "<class '__main__.LSTM'>\n",
      "<class '__main__.LSTM'>\n",
      "epoch 020 train_loss 0.02076676\n"
     ]
    }
   ],
   "source": [
    "input_size=2\n",
    "hidden_size=128\n",
    "num_layers=2\n",
    "output_size = 1\n",
    "batch_size = 1\n",
    "optimizer = 'adam'\n",
    "max_epochs = 25\n",
    "# lr = 0.05\n",
    "lr = 0.01   # mape:14.~    train_loss: 0.0037~\n",
    "\n",
    "step = 18\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "model_path = './lstm_model/best_model_lstm.model'\n",
    "\n",
    "data_train, data_validate, data_test, m, n = nn_seq_us(batch_size=batch_size, step=step)\n",
    "\n",
    "lstm_train(data_train, data_validate, model_path, input_size, hidden_size, num_layers, output_size, batch_size, optimizer, max_epochs, lr, device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading models...\n",
      "predicting...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (162,) (81,) ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [32]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mlstm_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [30]\u001B[0m, in \u001B[0;36mlstm_test\u001B[1;34m(data_test, path, m, n, input_size, hidden_size, num_layers, output_size, batch_size, device)\u001B[0m\n\u001B[0;32m     37\u001B[0m y \u001B[38;5;241m=\u001B[39m (m \u001B[38;5;241m-\u001B[39m n) \u001B[38;5;241m*\u001B[39m y \u001B[38;5;241m+\u001B[39m n\n\u001B[0;32m     38\u001B[0m pred \u001B[38;5;241m=\u001B[39m (m \u001B[38;5;241m-\u001B[39m n) \u001B[38;5;241m*\u001B[39m pred \u001B[38;5;241m+\u001B[39m n\n\u001B[1;32m---> 39\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmape:\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[43mget_mape\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse:\u001B[39m\u001B[38;5;124m'\u001B[39m, get_mse(y, pred))\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# plot\u001B[39;00m\n",
      "Input \u001B[1;32mIn [30]\u001B[0m, in \u001B[0;36mget_mape\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124;03mCompute mean absolute percentage error (MAPE)\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     14\u001B[0m y_true, y_pred \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(y_true), np\u001B[38;5;241m.\u001B[39marray(y_pred)\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmean(np\u001B[38;5;241m.\u001B[39mabs((\u001B[43my_true\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m) \u001B[38;5;241m/\u001B[39m y_true)) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m\n",
      "\u001B[1;31mValueError\u001B[0m: operands could not be broadcast together with shapes (162,) (81,) "
     ]
    }
   ],
   "source": [
    "lstm_test(data_test, model_path, m, n, input_size, hidden_size, num_layers, output_size, batch_size, device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "(378, 147)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.__len__(), data_validate.__len__()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading models...\n",
      "predicting...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 4",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [28]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mfuture_lstm_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [25]\u001B[0m, in \u001B[0;36mfuture_lstm_test\u001B[1;34m(data_test, path, m, n, input_size, hidden_size, num_layers, output_size, batch_size, device)\u001B[0m\n\u001B[0;32m     81\u001B[0m seq \u001B[38;5;241m=\u001B[39m ss[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 83\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;66;03m# print(f'seq{seq};')\u001B[39;00m\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(seq[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m):\n",
      "File \u001B[1;32mD:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[1;34m(self, input_seq)\u001B[0m\n\u001B[0;32m     19\u001B[0m c_0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_directions \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# output(batch_size, seq_len, num_directions * hidden_size)\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m output, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_seq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mh_0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc_0\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# output(5, 30, 64)\u001B[39;00m\n\u001B[0;32m     22\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear(output)  \u001B[38;5;66;03m# (5, 30, 1)\u001B[39;00m\n\u001B[0;32m     23\u001B[0m pred \u001B[38;5;241m=\u001B[39m pred[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :]  \u001B[38;5;66;03m# (5, 1)\u001B[39;00m\n",
      "File \u001B[1;32mD:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:689\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    684\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    685\u001B[0m     \u001B[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001B[39;00m\n\u001B[0;32m    686\u001B[0m     \u001B[38;5;66;03m# the user believes he/she is passing in.\u001B[39;00m\n\u001B[0;32m    687\u001B[0m     hx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpermute_hidden(hx, sorted_indices)\n\u001B[1;32m--> 689\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_forward_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_sizes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    691\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers,\n\u001B[0;32m    692\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first)\n",
      "File \u001B[1;32mD:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:632\u001B[0m, in \u001B[0;36mLSTM.check_forward_args\u001B[1;34m(self, input, hidden, batch_sizes)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_forward_args\u001B[39m(\u001B[38;5;28mself\u001B[39m,  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[0;32m    628\u001B[0m                        \u001B[38;5;28minput\u001B[39m: Tensor,\n\u001B[0;32m    629\u001B[0m                        hidden: Tuple[Tensor, Tensor],\n\u001B[0;32m    630\u001B[0m                        batch_sizes: Optional[Tensor],\n\u001B[0;32m    631\u001B[0m                        ):\n\u001B[1;32m--> 632\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_sizes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    633\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_hidden_size(hidden[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_expected_hidden_size(\u001B[38;5;28minput\u001B[39m, batch_sizes),\n\u001B[0;32m    634\u001B[0m                            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected hidden[0] size \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    635\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_hidden_size(hidden[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_expected_cell_size(\u001B[38;5;28minput\u001B[39m, batch_sizes),\n\u001B[0;32m    636\u001B[0m                            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected hidden[1] size \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mD:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:201\u001B[0m, in \u001B[0;36mRNNBase.check_input\u001B[1;34m(self, input, batch_sizes)\u001B[0m\n\u001B[0;32m    199\u001B[0m expected_input_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m3\u001B[39m\n\u001B[0;32m    200\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m expected_input_dim:\n\u001B[1;32m--> 201\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    202\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput must have \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m dimensions, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    203\u001B[0m             expected_input_dim, \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim()))\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_size \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    206\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput.size(-1) must be equal to input_size. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    207\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_size, \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: input must have 3 dimensions, got 4"
     ]
    }
   ],
   "source": [
    "future_lstm_test(data_test, model_path, m, n, input_size, hidden_size, num_layers, output_size, batch_size, device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def list_of_groups(data, sub_len):\n",
    "    groups = zip(*(iter(data),) * sub_len)\n",
    "    end_list = [list(i) for i in groups]\n",
    "    count = len(data) % sub_len\n",
    "    end_list.append(data[-count:]) if count != 0 else end_list\n",
    "    return end_list\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "[(tensor([[[0.8111],\n           [0.7944],\n           [0.8977],\n           [0.8184],\n           [0.8935],\n           [0.8894],\n           [0.9812],\n           [1.0522],\n           [0.9958],\n           [1.2495],\n           [1.3382],\n           [1.4509],\n           [1.4301],\n           [1.6722],\n           [1.5783],\n           [1.5511],\n           [1.4363],\n           [1.3111],\n           [1.3100],\n           [1.2161],\n           [1.3288],\n           [1.4019],\n           [1.2129],\n           [1.4154]]]),\n  tensor([[1.4415]]))]"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [(x, label) for (x, label) in iter(data_test)]\n",
    "test[0:1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './practice/covid19/lstm_model/best_model_lstm.model'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 49>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     45\u001B[0m                 \u001B[38;5;66;03m# print(y_pred)\u001B[39;00m\n\u001B[0;32m     46\u001B[0m                 sub_pred\u001B[38;5;241m.\u001B[39mextend(y_pred)\n\u001B[1;32m---> 49\u001B[0m \u001B[43mss_rolling_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./practice/covid19/lstm_model/best_model_lstm.model\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36mss_rolling_test\u001B[1;34m(data_test, input_size, hidden_size, num_layers, output_size, batch_size, device, path, m, n, pred_step_size)\u001B[0m\n\u001B[0;32m      3\u001B[0m y \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m LSTM(input_size, hidden_size, num_layers, output_size, device\u001B[38;5;241m=\u001B[39mdevice, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m----> 6\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodels\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      7\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicting...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mD:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\serialization.py:594\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    592\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 594\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m    596\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m    597\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m    598\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m    599\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32mD:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\serialization.py:230\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 230\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    231\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    232\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32mD:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\serialization.py:211\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 211\u001B[0m     \u001B[38;5;28msuper\u001B[39m(_open_file, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './practice/covid19/lstm_model/best_model_lstm.model'"
     ]
    }
   ],
   "source": [
    "def ss_rolling_test(data_test, input_size, hidden_size, num_layers, output_size, batch_size, device, path, m, n, pred_step_size):\n",
    "    pred = []\n",
    "    y = []\n",
    "\n",
    "    model = LSTM(input_size, hidden_size, num_layers, output_size, device=device, batch_size=batch_size).to(device)\n",
    "    model.load_state_dict(torch.load(path)['models'])\n",
    "    model.eval()\n",
    "\n",
    "    print('predicting...')\n",
    "\n",
    "    data_test = [x for x in iter(data_test)]\n",
    "\n",
    "    data_test = list_of_groups(data_test, pred_step_size)\n",
    "\n",
    "    for sub_item in data_test:\n",
    "        sub_pred = []\n",
    "        for seq_idx, (seq, label) in enumerate(sub_item, 0):\n",
    "            label = list(chain.from_iterable(label.data.tolist()))\n",
    "            y.extend(label)\n",
    "            # print(y)\n",
    "            if seq_idx != 0:\n",
    "                seq = seq.cpu().numpy().tolist()[0]\n",
    "                if len(sub_pred) >= len(seq):\n",
    "                    for t in range(len(seq)):\n",
    "                        seq[t][0] = sub_pred[len(sub_pred) - len(seq) + t]\n",
    "                else:\n",
    "                    for t in range(len(sub_pred)):\n",
    "                        seq[len(seq) - len(sub_pred) + t][0] = sub_pred[t]\n",
    "            else:\n",
    "                seq = seq.cpu().numpy().tolist()[0]\n",
    "\n",
    "\n",
    "            # print(new_seq)\n",
    "            seq = [seq]\n",
    "            seq = torch.FloatTensor(seq)\n",
    "            seq = MyDataset(seq)\n",
    "            seq = DataLoader(dataset=seq, batch_size=1, shuffle=False, num_workers=0)\n",
    "            # print(new_seq)\n",
    "            seq = [x for x in iter(seq)][0]\n",
    "            # print(new_seq)\n",
    "            with torch.no_grad():\n",
    "                seq = seq.to(device)\n",
    "                y_pred = model(seq)\n",
    "                y_pred = list(chain.from_iterable(y_pred.data.tolist()))\n",
    "                # print(y_pred)\n",
    "                sub_pred.extend(y_pred)\n",
    "\n",
    "\n",
    "ss_rolling_test(data_test, input_size, hidden_size, num_layers, output_size, batch_size, device, \"./practice/covid19/lstm_model/best_model_lstm.model\", m, n, 12)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
