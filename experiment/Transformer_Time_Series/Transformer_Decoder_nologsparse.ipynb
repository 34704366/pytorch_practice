{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import causal_convolution_layer\n",
    "import Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerTimeSeries(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Time Series application of transformers based on paper\n",
    "    \n",
    "    causal_convolution_layer parameters:\n",
    "        in_channels: the number of features per time point\n",
    "        out_channels: the number of features outputted per time point\n",
    "        kernel_size: k is the width of the 1-D sliding kernel\n",
    "        \n",
    "    nn.Transformer parameters:\n",
    "        d_model: the size of the embedding vector (input)\n",
    "    \n",
    "    PositionalEncoding parameters:\n",
    "        d_model: the size of the embedding vector (positional vector)\n",
    "        dropout: the dropout to be used on the sum of positional+embedding vector\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TransformerTimeSeries,self).__init__()\n",
    "        self.input_embedding = causal_convolution_layer.context_embedding(2,256,9)\n",
    "        self.positional_embedding = torch.nn.Embedding(512,256)\n",
    "\n",
    "        \n",
    "        self.decode_layer = torch.nn.TransformerEncoderLayer(d_model=256,nhead=8)\n",
    "        self.transformer_decoder = torch.nn.TransformerEncoder(self.decode_layer, num_layers=3)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(256,1)\n",
    "        \n",
    "    def forward(self,x,y,attention_masks):\n",
    "        \n",
    "        # concatenate observed points and time covariate\n",
    "        # (B*feature_size*n_time_points)\n",
    "        z = torch.cat((y.unsqueeze(1),x.unsqueeze(1)),1)\n",
    "\n",
    "        # input_embedding returns shape (Batch size,embedding size,sequence len) -> need (sequence len,Batch size,embedding_size)\n",
    "        z_embedding = self.input_embedding(z).permute(2,0,1)\n",
    "        \n",
    "        # get my positional embeddings (Batch size, sequence_len, embedding_size) -> need (sequence len,Batch size,embedding_size)\n",
    "        positional_embeddings = self.positional_embedding(x.type(torch.long)).permute(1,0,2)\n",
    "        \n",
    "        input_embedding = z_embedding+positional_embeddings\n",
    "        \n",
    "        transformer_embedding = self.transformer_decoder(input_embedding,attention_masks)\n",
    "\n",
    "        output = self.fc1(transformer_embedding.permute(1,0,2))\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 4500*48 fx: 4500*48\n",
      "x: 500*48 fx: 500*48\n",
      "x: 1000*48 fx: 1000*48\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = Dataloader.time_series_decoder_missing_paper(t0,4500) # missing\n",
    "# validation_dataset = Dataloader.time_series_decoder_missing_paper(t0,500) # missing \n",
    "# test_dataset = Dataloader.time_series_decoder_missing_paper(t0,1000) # missing\n",
    "\n",
    "train_dataset = Dataloader.time_series_decoder_paper(t0,4500)\n",
    "validation_dataset = Dataloader.time_series_decoder_paper(t0,500)\n",
    "test_dataset = Dataloader.time_series_decoder_paper(t0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "validation_dl = DataLoader(validation_dataset,batch_size=64)\n",
    "test_dl = DataLoader(test_dataset,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerTimeSeries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .0005 # learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dp(y_pred,y_true,q):\n",
    "    return max([q*(y_pred-y_true),(q-1)*(y_pred-y_true)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rp_num_den(y_preds,y_trues,q):\n",
    "    numerator = np.sum([Dp(y_pred,y_true,q) for y_pred,y_true in zip(y_preds,y_trues)])\n",
    "    denominator = np.sum([np.abs(y_true) for y_true in y_trues])\n",
    "    return numerator,denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,train_dl,t0=96):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    n = 0\n",
    "    for step,(x,y,attention_masks) in enumerate(train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x.cuda(),y.cuda(),attention_masks[0].cuda())\n",
    "        loss = criterion(output.squeeze()[:,(t0-1):(t0+24-1)],y.cuda()[:,t0:]) # not missing data\n",
    "        # loss = criterion(output.squeeze()[:,(t0-1-10):(t0+24-1-10)],y.cuda()[:,(t0-10):]) # missing data\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += (loss.detach().cpu().item() * x.shape[0])\n",
    "        n += x.shape[0]\n",
    "    return train_loss/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model,validation_dl,t0=96):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for step,(x,y,attention_masks) in enumerate(validation_dl):\n",
    "            output = model(x.cuda(),y.cuda(),attention_masks[0].cuda())\n",
    "            loss = criterion(output.squeeze()[:,(t0-1):(t0+24-1)],y.cuda()[:,t0:]) # not missing data\n",
    "            # loss = criterion(output.squeeze()[:,(t0-1-10):(t0+24-1-10)],y.cuda()[:,(t0-10):]) # missing data\n",
    "            \n",
    "            eval_loss += (loss.detach().cpu().item() * x.shape[0])\n",
    "            n += x.shape[0]\n",
    "            \n",
    "    return eval_loss/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model,test_dl,t0=96):\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        observations = []\n",
    "\n",
    "        model.eval()\n",
    "        for step,(x,y,attention_masks) in enumerate(test_dl):\n",
    "            output = model(x.cuda(),y.cuda(),attention_masks[0].cuda())\n",
    "\n",
    "            for p,o in zip(output.squeeze()[:,(t0-1):(t0+24-1)].cpu().numpy().tolist(),y.cuda()[:,t0:].cpu().numpy().tolist()): # not missing data\n",
    "            #for p,o in zip(output.squeeze()[:,(t0-1-10):(t0+24-1-10)].cpu().numpy().tolist(),y.cuda()[:,(t0-10):].cpu().numpy().tolist()): # missing data\n",
    "\n",
    "\n",
    "                predictions.append(p)\n",
    "                observations.append(o)\n",
    "\n",
    "        num = 0\n",
    "        den = 0\n",
    "        for y_preds,y_trues in zip(predictions,observations):\n",
    "            num_i,den_i = Rp_num_den(y_preds,y_trues,.5)\n",
    "            num+=num_i\n",
    "            den+=den_i\n",
    "        Rp = (2*num)/den\n",
    "        \n",
    "    return Rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [19]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      6\u001B[0m eval_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 8\u001B[0m l_t \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\u001B[43mt0\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m train_loss\u001B[38;5;241m.\u001B[39mappend(l_t)\n\u001B[0;32m     11\u001B[0m l_e \u001B[38;5;241m=\u001B[39m eval_epoch(model,validation_dl,t0)\n",
      "Input \u001B[1;32mIn [16]\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[1;34m(model, train_dl, t0)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step,(x,y,attention_masks) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dl):\n\u001B[0;32m      6\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 7\u001B[0m     output \u001B[38;5;241m=\u001B[39m model(\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m,y\u001B[38;5;241m.\u001B[39mcuda(),attention_masks[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mcuda())\n\u001B[0;32m      8\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(output\u001B[38;5;241m.\u001B[39msqueeze()[:,(t0\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):(t0\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m24\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)],y\u001B[38;5;241m.\u001B[39mcuda()[:,t0:]) \u001B[38;5;66;03m# not missing data\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m# loss = criterion(output.squeeze()[:,(t0-1-10):(t0+24-1-10)],y.cuda()[:,(t0-10):]) # missing data\u001B[39;00m\n",
      "File \u001B[1;32mD:\\soft\\Miniconda\\envs\\pytorch_practice_py38\\lib\\site-packages\\torch\\cuda\\__init__.py:208\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    205\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    206\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 208\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    209\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    211\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "train_epoch_loss = []\n",
    "eval_epoch_loss = []\n",
    "Rp_best = 10\n",
    "for e,epoch in enumerate(range(epochs)):\n",
    "    train_loss = []\n",
    "    eval_loss = []\n",
    "    \n",
    "    l_t = train_epoch(model,train_dl,t0)\n",
    "    train_loss.append(l_t)\n",
    "    \n",
    "    l_e = eval_epoch(model,validation_dl,t0)\n",
    "    eval_loss.append(l_e)\n",
    "    \n",
    "    Rp = test_epoch(model,test_dl,t0)\n",
    "\n",
    "    if Rp_best > Rp:\n",
    "        Rp_best = Rp\n",
    "        \n",
    "    train_epoch_loss.append(np.mean(train_loss))\n",
    "    eval_epoch_loss.append(np.mean(eval_loss))\n",
    "    \n",
    "    print(\"Epoch {}: Train loss: {} \\t Validation loss: {} \\t R_p={}\".format(e,\n",
    "                                                             np.mean(train_loss),\n",
    "                                                             np.mean(eval_loss),Rp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rp best={}\".format(Rp_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(train_epoch_loss)\n",
    "plt.plot(eval_epoch_loss)\n",
    "plt.legend(['Train Loss','Eval Loss'],fontsize=25)\n",
    "plt.xlabel(\"Epoch\",fontsize=25)\n",
    "plt.ylabel(\"MSE Loss\",fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_plots = 5\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for step,(x,y,attention_masks) in enumerate(test_dl):\n",
    "            output = model(x.cuda(),y.cuda(),attention_masks[0].cuda())\n",
    "\n",
    "            if step > n_plots:\n",
    "                break\n",
    "\n",
    "            with torch.no_grad():\n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.plot(x[0].cpu().detach().squeeze().numpy(),y[0].cpu().detach().squeeze().numpy(),'g--',linewidth=3)\n",
    "                plt.plot(x[0,t0:].cpu().detach().squeeze().numpy(),output[0,(t0-1):(t0+24-1)].cpu().detach().squeeze().numpy(),'b--',linewidth=3) # not missing data\n",
    "                # plt.plot(x[0,(t0-10):].cpu().detach().squeeze().numpy(),output[0,(t0-1-10):(t0+24-1-10)].cpu().detach().squeeze().numpy(),'b--',linewidth=3) # missing data\n",
    "                plt.xlabel(\"x\",fontsize=20)\n",
    "                plt.legend([\"$[0,t_0+24)_{obs}$\",\"$[t_0,t_0+24)_{predicted}$\"])\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn(model,x,y,attention_masks):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x=x.cuda(); y=y.cuda(); attention_masks = attention_masks.cuda()\n",
    "        z = torch.cat((y.unsqueeze(1),x.unsqueeze(1)),1)\n",
    "        z_embedding = model.input_embedding(z).permute(2,0,1)\n",
    "        positional_embeddings = model.positional_embedding(x.type(torch.long)).permute(1,0,2)\n",
    "        input_embedding = z_embedding+positional_embeddings\n",
    "                \n",
    "        attn_layer_i = []\n",
    "        for layer in model.transformer_decoder.layers:\n",
    "            attn_layer_i.append(layer.self_attn(input_embedding,input_embedding,input_embedding,attn_mask=attention_masks)[-1].squeeze().cpu().detach().numpy())\n",
    "            input_embedding = layer.forward(input_embedding,attention_masks)\n",
    "        \n",
    "        return attn_layer_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_example = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_layers = get_attn(model,test_dataset[idx_example][0].unsqueeze(0),test_dataset[idx_example][1].unsqueeze(0),test_dataset[idx_example][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(test_dataset[idx_example][0].numpy(),train_dataset[10][1].numpy())\n",
    "plt.plot([t0+24-1,t0+24-1],[20,120],'g--') # not missing data\n",
    "# plt.plot([t0+24-1,t0+24-1],[20,120],'g--') # missing data\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(attn_layers[0][t0+24-1]) # not missing data\n",
    "plt.plot(attn_layers[1][t0+24-1]) # not missing data\n",
    "plt.plot(attn_layers[2][t0+24-1]) # not missing data\n",
    "\n",
    "#plt.plot(train_dataset[idx_example][0].numpy(),attn_layers[0][119-10]) # missing data\n",
    "#plt.plot(train_dataset[idx_example][0].numpy(),attn_layers[1][119-10]) # missing data\n",
    "#plt.plot(train_dataset[idx_example][0].numpy(),attn_layers[2][119-10]) # missing data\n",
    "\n",
    "\n",
    "\n",
    "plt.legend([\"attn score in layer 1\",\"attn score in layer 2\",\"attn score in layer 3\"])\n",
    "plt.title(\"Attn for t = 119\") # not missing data\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
